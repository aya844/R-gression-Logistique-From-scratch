{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8889e640",
   "metadata": {},
   "source": [
    "# TP : Régression Logistique (from scratch) — Méthode de la Descente de Gradient\n",
    "\n",
    "Dans ce notebook, nous implémentons la régression logistique entièrement depuis les formules mathématiques, sans utiliser `sklearn` pour l'entraînement.\n",
    "\n",
    "Nous utiliserons le dataset *Pima Indians Diabetes Database* (Kaggle), où la variable cible est binaire (diagnostic diabète = 1 / non diabétique = 0), et nous choisirons **une seule variable explicative** pour respecter les consignes du TP.\n",
    "\n",
    "L’objectif est de :\n",
    "- dériver la log-vraisemblance,\n",
    "- calculer son gradient,\n",
    "- coder une descente de gradient (maximisation),\n",
    "- entraîner le modèle et comparer avec `sklearn`.\n",
    "\n",
    "\n",
    "Référence : https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database."
   ]
  },
  {
   "cell_type": "code",
   "id": "9480c3b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:05:02.274575Z",
     "start_time": "2025-12-06T21:05:02.260829Z"
    }
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Charger le dataset (téléchargez pima-indians-diabetes.csv et placez-le dans data/)\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modèle statistique et log-vraisemblance\n",
    "\n",
    "Nous considérons le modèle logistique :\n",
    "\n",
    "$$\n",
    "p(x_i) = \\sigma(\\beta_0 + \\beta_1 x_i)\n",
    "= \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_i)}}.\n",
    "$$\n",
    "\n",
    "Pour des données $(x_i, y_i)$ où $y_i \\in \\{0,1\\}$, la log-vraisemblance est :\n",
    "\n",
    "$$\n",
    "\\ell(\\beta_0,\\beta_1)\n",
    "= \\sum_{i=1}^n \\left[\n",
    "y_i \\log(p_i) + (1-y_i)\\log(1 - p_i)\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "### Gradient de la log-vraisemblance\n",
    "\n",
    "En dérivant :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial \\beta_0}\n",
    "= \\sum_{i=1}^n (y_i - p_i),\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell}{\\partial \\beta_1}\n",
    "= \\sum_{i=1}^n x_i (y_i - p_i).\n",
    "$$\n",
    "\n",
    "Notons :\n",
    "\n",
    "$$\n",
    "\\nabla \\ell(\\beta)\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\sum (y_i - p_i) \\\\\n",
    "\\sum x_i (y_i - p_i)\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "### Mise à jour de la descente de gradient (maximisation)\n",
    "\n",
    "Comme on maximise $\\ell$ :\n",
    "\n",
    "$$\n",
    "\\beta^{(t+1)} = \\beta^{(t)} + \\eta \\, \\nabla \\ell(\\beta^{(t)}).\n",
    "$$\n",
    "\n",
    "où $\\eta > 0$ est le pas d’apprentissage.\n",
    "\n"
   ],
   "id": "6c4b8c5d25024221"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Préparation des données\n",
    "\n",
    "Nous utilisons le dataset Pima Diabetes.\n",
    "\n",
    "### Pourquoi standardiser la variable explicative ?\n",
    "\n",
    "Avant d’entraîner un modèle logistique par optimisation numérique, il est essentiel de **standardiser** la variable explicative :\n",
    "\n",
    "$$\n",
    "X_{\\text{std}} = \\frac{X - \\mu_X}{\\sigma_X}.\n",
    "$$\n",
    "\n",
    "Cette transformation ramène les données à une moyenne 0 et un écart-type 1.\n",
    "\n",
    "En optimisation, cela apporte plusieurs avantages :\n",
    "- la descente de gradient est plus stable et plus rapide ;\n",
    "- l’algorithme évite les oscillations (‘zigzag’) lorsque l’échelle des données est grande ;\n",
    "- le choix du learning rate devient plus simple et moins sensible.\n",
    "\n",
    "\n",
    "Pour respecter la consigne du TP, nous ne retenons qu'une seule variable explicative, par exemple :\n",
    "- `Glucose`\n",
    "- (autres options possibles : BMI, Age, BloodPressure…)\n",
    "\n",
    "Nous séparons ensuite les données en deux échantillons : apprentissage et test.\n"
   ],
   "id": "750d5b819daff56a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:12:00.199044Z",
     "start_time": "2025-12-06T21:12:00.192921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature = 'Glucose'\n",
    "X = df[[feature]].values.astype(float)\n",
    "y = df['Outcome'].values.astype(int)\n",
    "\n",
    "# Standardiser X\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X).reshape(-1)  # vecteur shape (n,)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.5, random_state=0)\n",
    "n = len(X_train)\n"
   ],
   "id": "e5f9f5ad62a0e19e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3e34d46a53b4e9ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Implémentation du modèle logistique et de son gradient\n",
    "\n",
    "Nous définissons :\n",
    "\n",
    "- la fonction logistique (sigmoid),\n",
    "- la log-vraisemblance,\n",
    "- le gradient,\n",
    "- puis la descente de gradient.\n",
    "\n",
    "L’objectif est de maximiser $\\ell(\\beta)$.\n"
   ],
   "id": "fb622212e294a336"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:22:07.394060Z",
     "start_time": "2025-12-06T21:22:07.388919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def log_vraisemblance(beta, X, y):\n",
    "    # beta: array([b0, b1])\n",
    "    z = beta[0] + beta[1]*X\n",
    "    p = sigmoid(z)\n",
    "    eps = 1e-12\n",
    "    return np.sum(y*np.log(p+eps) + (1-y)*np.log(1-p+eps))\n",
    "\n",
    "def gradient(beta, X, y):\n",
    "    z = beta[0] + beta[1]*X\n",
    "    p = sigmoid(z)\n",
    "    g0 = np.sum(y - p)\n",
    "    g1 = np.sum(X * (y - p))\n",
    "    return np.array([g0, g1])\n"
   ],
   "id": "2c132975978217d8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:22:23.690258Z",
     "start_time": "2025-12-06T21:22:23.680328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_ascent(X, y, lr=0.01, max_iter=2000, tol=1e-6, verbose=False):\n",
    "    beta = np.zeros(2)\n",
    "    history = {'ll':[], 'beta':[]}\n",
    "    for k in range(max_iter):\n",
    "        g = gradient(beta, X, y)\n",
    "        beta = beta + lr * g\n",
    "        ll = log_vraisemblance(beta, X, y)\n",
    "        history['ll'].append(ll)\n",
    "        history['beta'].append(beta.copy())\n",
    "        if np.linalg.norm(lr*g) < tol:\n",
    "            if verbose: print(f\"Converged at iter {k}\")\n",
    "            break\n",
    "        # optional: reduce lr if ll decreases (simple safeguard)\n",
    "        if k>0 and history['ll'][-1] < history['ll'][-2]:\n",
    "            lr *= 0.5\n",
    "    return beta, history\n",
    "\n",
    "beta_gd, hist_gd = gradient_ascent(X_train, y_train, lr=0.01, max_iter=5000, verbose=True)\n",
    "beta_gd\n"
   ],
   "id": "8d569a4ae1aa2876",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iter 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.75108379,  1.14686835])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analyse des performances\n",
    "\n",
    "Nous évaluons :\n",
    "- l'accuracy,\n",
    "- l'AUC,\n",
    "- et comparons nos coefficients estimés avec ceux de `sklearn.linear_model.LogisticRegression`.\n",
    "\n",
    "Cela permet de valider l'exactitude de notre implémentation from scratch.\n"
   ],
   "id": "b09115b009dea908"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:16:11.954135Z",
     "start_time": "2025-12-06T21:16:11.946167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prédictions\n",
    "def predict_prob(beta, X):\n",
    "    return sigmoid(beta[0] + beta[1]*X)\n",
    "\n",
    "def predict(beta, X, thr=0.5):\n",
    "    return (predict_prob(beta, X) >= thr).astype(int)\n",
    "\n",
    "y_pred_train = predict(beta_gd, X_train)\n",
    "y_pred_test  = predict(beta_gd, X_test)\n",
    "\n",
    "print(\"Train accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test  accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Test AUC:\", roc_auc_score(y_test, predict_prob(beta_gd, X_test)))\n"
   ],
   "id": "b6403ba8bf44f8ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.75\n",
      "Test  accuracy: 0.7421875\n",
      "Test AUC: 0.7981021633527441\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:17:15.985763Z",
     "start_time": "2025-12-06T21:17:15.977139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# comparaison avec sklearn (fit intercept = True)\n",
    "X_train_2d = X_train.reshape(-1,1)\n",
    "X_test_2d  = X_test.reshape(-1,1)\n",
    "clf = LogisticRegression(solver='lbfgs').fit(X_train_2d, y_train)\n",
    "beta_sklearn = np.array([clf.intercept_[0], clf.coef_[0,0]])\n",
    "print(\"Sklearn beta:\", beta_sklearn)\n",
    "print(\"Notre beta   :\", beta_gd)\n"
   ],
   "id": "b1968603e9697aab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn beta: [-0.74658524  1.12416839]\n",
      "Notre beta   : [-0.75108379  1.14686835]\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
